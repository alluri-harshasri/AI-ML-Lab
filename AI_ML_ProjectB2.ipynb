{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "SMqBKL2gZbJC",
        "YrEajKbRNMk-",
        "mm2VjS2_P9cW",
        "BmRJYZbYx-BQ",
        "oPKXhbNE4OHq",
        "7DnF0BIRU6nD",
        "1AWfB7nG0H2e",
        "WQG5eY94h11d",
        "Fbce5RzanIS4",
        "KM4kSKcOt0it"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alluriharshasri/AI-ML-Lab/blob/main/AI_ML_ProjectB2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMqBKL2gZbJC"
      },
      "source": [
        "## **Project Objective**\n",
        "\n",
        "**Dataset:** Kaggle's Amazon Employee Access Challenge dataset\n",
        "\n",
        "The aim of this project is to develop a model using historical data that can effectively determine an employee's access requirements, thereby minimizing manual access transactions such as grants and revokes as the employee's attributes evolve over time. The model will take into account an employee's role information and a resource code to predict whether access should be granted or not.\n",
        "\n",
        "The dataset comprises real historical data collected between 2010 and 2011. Access to resources has been manually approved or denied for employees over time. The task is to create an algorithm capable of learning from this historical data to predict approval or denial for a new set of employees.\n",
        "\n",
        "**File Descriptions:**\n",
        "- *train.csv:* This file contains the training set. Each row includes the ACTION (ground truth), RESOURCE, and details about the employee's role at the time of approval.\n",
        "- *test.csv:* This file comprises the test set for which predictions are required. Each row in this file asks whether an employee with the listed characteristics should have access to the listed resource."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l47BBNV2MQpi"
      },
      "source": [
        "### **Project Index**\n",
        "\n",
        "1. Data collection - Import and Read Data\n",
        "\n",
        "2. Data Pre-processing\n",
        "  \n",
        "   a. Data Transformation\n",
        "   \n",
        "   b. Data Splitting\n",
        "\n",
        "3. Models\n",
        "\n",
        "   a. Model 1 - Logistic Regression Model\n",
        "\n",
        "   b. Model 2 - Support Vector Machines (SVM)\n",
        "\n",
        "   c. Model 3 - Decision Tree Model\n",
        "\n",
        "   d. Model 4 - K-Nearest Neighbors (K-NN) Model\n",
        "\n",
        "4. Model comparision and Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YrEajKbRNMk-"
      },
      "source": [
        "## **1. Data collection- Import and Read Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "susS1Gi0NRGg"
      },
      "source": [
        "#Importing all necessory librariies\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn import metrics\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from IPython import display\n",
        "from matplotlib import cm\n",
        "from matplotlib import gridspec\n",
        "from tensorflow.python.data import Dataset\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn import svm\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LsK_x1UNfbi",
        "outputId": "2273388f-d58a-4e8c-9347-feade34f36e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "source": [
        "# Reading training dataset\n",
        "\n",
        "train_dataframe = pd.read_csv(\"/content/train.csv\", sep=\",\")\n",
        "train_dataframe = train_dataframe.reindex(np.random.permutation(train_dataframe.index))\n",
        "\n",
        "train_dataframe.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/train.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-c84599b64797>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Reading training dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_dataframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/train.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtrain_dataframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dataframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    910\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1661\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1662\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1663\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/train.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTIo0XQpNypM"
      },
      "source": [
        "# Reading test dataset\n",
        "\n",
        "test_dataframe = pd.read_csv(\"/content/test.csv\", sep=\",\")\n",
        "test_dataframe = test_dataframe.reindex(np.random.permutation(test_dataframe.index))\n",
        "\n",
        "test_dataframe.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3jPOjOhQdlo"
      },
      "source": [
        "#Checking dataframe shapes for both datasets\n",
        "\n",
        "print(\"Training dataframe shape: \",train_dataframe.shape)\n",
        "print(\"Test dataframe shape: \",test_dataframe.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozJrIiY1ZJKl"
      },
      "source": [
        "# checking count of each categories for the target variable in the training dataframe\n",
        "\n",
        "print(train_dataframe['ACTION'].value_counts())\n",
        "sns.countplot(x='ACTION',data = train_dataframe, palette='hls')\n",
        "plt.title(\"Action class distribution\")\n",
        "plt.show()\n",
        "plt.savefig('count_plot_training')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mm2VjS2_P9cW"
      },
      "source": [
        "## **2. Data Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssLohlt0QI_S"
      },
      "source": [
        "#1. Handling Missing Data\n",
        "# Checking if there is any missing value in the dataset\n",
        "\n",
        "train_dataframe.isnull().sum()\n",
        "\n",
        "#2. Handling Outliers\n",
        "# As the dataset contains categoral and binary data, there is no need to check outliers as categiorical data means\n",
        "# It's just the composition of the sample which you have selected."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bq2hdUiGR5GC"
      },
      "source": [
        "#3. Feature selection\n",
        "#As there are no missing values and outliers, let's proceed with finding unique categories for each column\n",
        "train_dataframe.apply(lambda x: len(x.unique()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0YOmbhLSfrh"
      },
      "source": [
        "# Checking distributions of all variables\n",
        "f, axes = plt.subplots(3, 3, figsize=(15, 10), sharex=True)\n",
        "sns.despine(left=True)\n",
        "\n",
        "# distribution of RESOURCE\n",
        "RESOURCE= sns.distplot(train_dataframe['RESOURCE'].values, ax = axes[0,0])\n",
        "RESOURCE.title.set_text(\"RESOURCE distribution\")\n",
        "\n",
        "# distribution of MGR_ID\n",
        "MGR_ID= sns.distplot(train_dataframe['MGR_ID'].values, ax = axes[0,1])\n",
        "MGR_ID.title.set_text(\"MGR_ID distribution\")\n",
        "\n",
        "# distribution of ROLE_ROLLUP_1\n",
        "ROLE_ROLLUP_1= sns.distplot(train_dataframe['ROLE_ROLLUP_1'].values, ax = axes[0,2])\n",
        "ROLE_ROLLUP_1.title.set_text(\"ROLE_ROLLUP_1 distribution\")\n",
        "\n",
        "# distribution of ROLE_ROLLUP_2\n",
        "ROLE_ROLLUP_2= sns.distplot(train_dataframe['ROLE_ROLLUP_2'].values, ax = axes[1,0])\n",
        "ROLE_ROLLUP_2.title.set_text(\"ROLE_ROLLUP_2 distribution\")\n",
        "\n",
        "# distribution of ROLE_DEPTNAME\n",
        "ROLE_DEPTNAME= sns.distplot(train_dataframe['ROLE_DEPTNAME'].values, ax = axes[1,1])\n",
        "ROLE_DEPTNAME.title.set_text(\"ROLE_DEPTNAME distribution\")\n",
        "\n",
        "# distribution of ROLE_TITLE\n",
        "ROLE_TITLE= sns.distplot(train_dataframe['ROLE_TITLE'].values, ax = axes[1,2])\n",
        "ROLE_TITLE.title.set_text(\"ROLE_TITLE distribution\")\n",
        "\n",
        "# distribution of ROLE_FAMILY_DESC\n",
        "ROLE_FAMILY_DESC= sns.distplot(train_dataframe['ROLE_FAMILY_DESC'].values, ax = axes[2,0])\n",
        "ROLE_FAMILY_DESC.title.set_text(\"ROLE_FAMILY_DESC distribution\")\n",
        "\n",
        "# distribution of ROLE_FAMILY\n",
        "ROLE_FAMILY= sns.distplot(train_dataframe['ROLE_FAMILY'].values, ax = axes[2,1])\n",
        "ROLE_FAMILY.title.set_text(\"ROLE_FAMILY distribution\")\n",
        "\n",
        "# distribution of ROLE_CODE\n",
        "ROLE_CODE= sns.distplot(train_dataframe['ROLE_CODE'].values, ax = axes[2,2])\n",
        "ROLE_CODE.title.set_text(\"ROLE_CODE distribution\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GksA0x1UohqN"
      },
      "source": [
        "# heat map of correlation of features\n",
        "# They all have weak correlation with the target variable\n",
        "\n",
        "correlation_matrix = train_dataframe.corr()\n",
        "fig = plt.figure(figsize=(12,9))\n",
        "sns.heatmap(correlation_matrix,vmax=1,square = True, annot=True)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSDFITsw3fkB"
      },
      "source": [
        "# checking correlation between ROLE_TITLE, ROLE_CODE\n",
        "# They have weak correlation as well so we will not be dropping any variables.\n",
        "\n",
        "print(train_dataframe[[\"ROLE_TITLE\",\"ROLE_CODE\"]].corr())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eyK0hyuj6PLz"
      },
      "source": [
        "### **2.a. Data Transformation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vg5Wb2LgN4Ao"
      },
      "source": [
        "#As seen in the last result, there are some categorical variables hence using One hot encoder to transform data for analysis\n",
        "\n",
        "one_hot_encoder = OneHotEncoder(sparse=True, dtype=np.float32, handle_unknown='ignore')\n",
        "\n",
        "# Using One hot encoding on training dataset\n",
        "X_train_columns = [x for x in train_dataframe.columns if x!=\"ACTION\"]\n",
        "X = one_hot_encoder.fit_transform(train_dataframe[X_train_columns])\n",
        "\n",
        "# Using One hot encoding on test dataset\n",
        "X_test_columns = [x for x in test_dataframe.columns if x!=\"id\"]\n",
        "X_test = one_hot_encoder.transform(test_dataframe[X_test_columns])\n",
        "\n",
        "#Splitting target variable in y for training dataset\n",
        "y = train_dataframe[\"ACTION\"].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKucv5Oc8dHJ"
      },
      "source": [
        "# Checking the data after one hot encoding\n",
        "print(\"Training data: \",X[4])\n",
        "print(\"\\n Training Target: \",y)\n",
        "\n",
        "print(\"\\n Test data: \",X_test[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKweJJyZ6FXO"
      },
      "source": [
        "### **2.b.Data Splitting**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IA-LXM5-P3JW"
      },
      "source": [
        "#Spittting Training dataset into training and validation datasets (validation dataset= 20%, Training dataset = 80%)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dK09aZepRED"
      },
      "source": [
        "#Checking dataframe shapes after splitting and one hot encoding (which are now sparse matrix, which will be easy for analysis)\n",
        "\n",
        "print(\"Training dataframe shape: \", X_train.shape)\n",
        "print(\"Validation dataframe shape: \",X_val.shape)\n",
        "print(\"Test dataframe shape: \",X_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3. Models**\n"
      ],
      "metadata": {
        "id": "wpcUlOomCBPf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**a. Model 1 - Logistic Regression Model**"
      ],
      "metadata": {
        "id": "HES8mTHRDNl3"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2Y07uRc7ky4"
      },
      "source": [
        "# Building Logistic regression model\n",
        "\n",
        "model_logisticRegression = LogisticRegression( random_state=623,\n",
        "                                               solver = 'saga',\n",
        "                                               max_iter = 10000,\n",
        "                                               warm_start = False,\n",
        "                                               verbose = 1,\n",
        "                                               tol = 1e-5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cYnkAqz7qln"
      },
      "source": [
        "# Cross validating the Logistic regression model to check the score and summary of the model\n",
        "statistics_cv = cross_validate(model_logisticRegression, X_train, y_train, groups=None, scoring='roc_auc', cv=5, n_jobs=2, return_train_score = True)\n",
        "\n",
        "# Describing the summary of the Logistic regression model\n",
        "statistics_cv = pd.DataFrame(statistics_cv)\n",
        "statistics_cv.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUTXaPpJyTXV"
      },
      "source": [
        "# Model Fitting\n",
        "\n",
        "model_logisticRegression_history = model_logisticRegression.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5vBk1gewDlF"
      },
      "source": [
        "# Model evaluation\n",
        "\n",
        "Accuracy_Logistic_Regression = model_logisticRegression_history.score(X_val, y_val)\n",
        "print(\"Accuracy of Logistic Regression Model- Validation Dataset: %.3f%%\" % (Accuracy_Logistic_Regression*100.0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmMohb__iNRN"
      },
      "source": [
        "# Model evaluation\n",
        "\n",
        "Accuracy_Logistic_Regression = model_logisticRegression_history.score(X_train, y_train)\n",
        "print(\"Accuracy of Logistic Regression Model- Training Dataset: %.3f%%\" % (Accuracy_Logistic_Regression*100.0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eE9gjW0cihzv"
      },
      "source": [
        "# Confusion matrix for Validation dataset\n",
        "\n",
        "y_val_predictions = model_logisticRegression_history.predict(X_val)\n",
        "cm = metrics.confusion_matrix(y_val, y_val_predictions)\n",
        "print(cm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSX5RYBlkUQr"
      },
      "source": [
        "# Heat map for the confusion matrix\n",
        "\n",
        "plt.figure(figsize=(9,9))\n",
        "sns.heatmap(cm, annot=True, fmt=\".3f\", linewidths=.5, square = True, cmap = 'Blues_r');\n",
        "plt.ylabel('Actual label');\n",
        "plt.xlabel('Predicted label');\n",
        "plt.title(\"Accuracy- Logistic Regression\", size = 15);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmImO7B4xuEY"
      },
      "source": [
        "# Misclassification rate\n",
        "\n",
        "print(\"Misclassifcation rate of Logistic regression model: \",\n",
        "      (((cm[0][1] + cm[1][0])/cm.sum())*100), \"%\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sR79nKGDsVN"
      },
      "source": [
        "# Checking Logistic regression model summary of validation dataset\n",
        "\n",
        "print(classification_report(y_val, y_val_predictions))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DnXoMPcwDv6"
      },
      "source": [
        "# Model prediction of Test dataset\n",
        "\n",
        "y_test = model_logisticRegression_history.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sR7QC6Dhdq_V"
      },
      "source": [
        "# saving predictions in dataframe\n",
        "\n",
        "y_test_predictions = pd.DataFrame()\n",
        "y_test_predictions[\"id\"] = test_dataframe[\"id\"]\n",
        "y_test_predictions[\"ACTION\"] = y_test\n",
        "print(y_test_predictions)\n",
        "\n",
        "# Saving results to csv file\n",
        "\n",
        "y_test_predictions.to_csv(\"submission.csv\", index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZeEpkLgbGiQB"
      },
      "source": [
        "# Finding ACTION target variable for test dataframe\n",
        "\n",
        "print(y_test_predictions['ACTION'].value_counts())\n",
        "sns.countplot(x='ACTION',data = y_test_predictions, palette='hls')\n",
        "plt.show()\n",
        "plt.savefig('count_plot')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A10Nb82pI4bQ"
      },
      "source": [
        "# ROC curve for Logistic regression model\n",
        "# The receiver operating characteristic (ROC) curve is another common tool used with binary classifiers.\n",
        "# The dotted line represents the ROC curve of a purely random classifier; a good classifier stays as far away from that line as possible (toward the top-left corner).\n",
        "\n",
        "logit_roc_auc = roc_auc_score(y_val, model_logisticRegression_history.predict(X_val))\n",
        "fpr, tpr, thresholds = roc_curve(y_val, model_logisticRegression_history.predict_proba(X_val)[:,1])\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver operating characteristic')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.savefig('Log_ROC')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**b. Model 3 - Support Vector Machines (SVM)**"
      ],
      "metadata": {
        "id": "6mZHmi4DDkWL"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_647hMn4xtZd"
      },
      "source": [
        "# Building Support Vector Machines (SVM) model\n",
        "\n",
        "model_svm = svm.SVC()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGUoEqSEzO8Y"
      },
      "source": [
        "# Cross validating the Support Vector Machines (SVM) model to check the score and summary of the model\n",
        "\n",
        "statistics_cv = cross_validate(model_svm, X_train, y_train, groups=None, scoring='roc_auc', cv=5, n_jobs=2, return_train_score = True)\n",
        "\n",
        "statistics_cv = pd.DataFrame(statistics_cv)\n",
        "statistics_cv.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3AKbF7qzO8b"
      },
      "source": [
        "# Model Fitting\n",
        "\n",
        "model_svm_history = model_svm.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kcy3zXUzO8n"
      },
      "source": [
        "#Confusion matrix for Validation dataset\n",
        "\n",
        "y_val_predictions = model_svm_history.predict(X_val)\n",
        "cm_svm = metrics.confusion_matrix(y_val, y_val_predictions)\n",
        "print(cm_svm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bH3hWWszzO8p"
      },
      "source": [
        "# Heat map for the confusion matrix\n",
        "\n",
        "plt.figure(figsize=(9,9))\n",
        "sns.heatmap(cm_svm, annot=True, fmt=\".3f\", linewidths=.5, square = True, cmap = 'Blues_r');\n",
        "plt.ylabel('Actual label');\n",
        "plt.xlabel('Predicted label');\n",
        "plt.title(\"Accuracy- Support Vector Machines\", size = 15);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9K8ZywdZelkX"
      },
      "source": [
        "# Misclassification rate\n",
        "\n",
        "print(\"Misclassifcation rate of SVM Model: \",\n",
        "      (((cm_svm[0][1] + cm_svm[1][0])/cm_svm.sum())*100), \"%\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXpJUpGLzO8r"
      },
      "source": [
        "# Checking accuracy on validation dataset using model\n",
        "\n",
        "print(classification_report(y_val, y_val_predictions))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nDuupiNzO8e"
      },
      "source": [
        "# Model accuracy\n",
        "\n",
        "Accuracy_svm = model_svm_history.score(X_train, y_train)\n",
        "print(\"Accuracy of SVM Model- Training dataset: %.3f%%\" % (Accuracy_svm*100.0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pCXbB3zBFEd"
      },
      "source": [
        "# Model evaluation\n",
        "\n",
        "Accuracy_svm = model_svm_history.score(X_val, y_val)\n",
        "print(\"Accuracy of SVM Model- - Validation Dataset: %.3f%%\" % (Accuracy_svm*100.0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ionx5L2zO8g"
      },
      "source": [
        "#Predicting test dataset\n",
        "\n",
        "y_test = model_svm_history.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EyVhmD9wzO8i"
      },
      "source": [
        "#saving predictions in dataframe\n",
        "y_test_predictions = pd.DataFrame()\n",
        "y_test_predictions[\"id\"] = test_dataframe[\"id\"]\n",
        "y_test_predictions[\"ACTION\"] = y_test\n",
        "print(y_test_predictions)\n",
        "\n",
        "#Saving results to csv file\n",
        "y_test_predictions.to_csv(\"submission.csv\", index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_Fxi8aLhGGB"
      },
      "source": [
        "# Finding ACTION target variable for test dataframe\n",
        "\n",
        "count_Class= y_test_predictions['ACTION'].value_counts()\n",
        "\n",
        "print(\"Count of ACTION variable: \\n\",count_Class)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbrrQK_za0mb"
      },
      "source": [
        "# Pie chart for counts of ACTION target variable for test dataframe\n",
        "\n",
        "count_Class.plot(kind = 'pie',  autopct='%1.0f%%')\n",
        "plt.title('Pie chart of count of ACTION variable')\n",
        "plt.ylabel('')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**c. Decision Tree Model**"
      ],
      "metadata": {
        "id": "SdszJ3k8D4O1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Building Decision Tree model\n",
        "model_dt = DecisionTreeClassifier()"
      ],
      "metadata": {
        "id": "7uvuiXaUR66s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cross validating the Decision Tree model\n",
        "statistics_cv_dt = cross_validate(model_dt, X_train, y_train, groups=None, scoring='roc_auc', cv=5, n_jobs=2, return_train_score = True)\n",
        "statistics_cv_dt = pd.DataFrame(statistics_cv_dt)\n",
        "statistics_cv_dt.describe()"
      ],
      "metadata": {
        "id": "pXYleU2VR-Fg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the Decision Tree model\n",
        "model_dt_history = model_dt.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "i364XI3-R-ua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion matrix for Validation dataset\n",
        "y_val_predictions_dt = model_dt_history.predict(X_val)\n",
        "cm_dt = metrics.confusion_matrix(y_val, y_val_predictions_dt)\n",
        "print(cm_dt)"
      ],
      "metadata": {
        "id": "cCQYMA7uSEvk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Heat map for the confusion matrix\n",
        "plt.figure(figsize=(9,9))\n",
        "sns.heatmap(cm_dt, annot=True, fmt=\".3f\", linewidths=.5, square = True, cmap = 'Blues_r')\n",
        "plt.ylabel('Actual label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.title(\"Accuracy- Decision Tree\", size = 15)"
      ],
      "metadata": {
        "id": "5jnFvM31SGsj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Misclassification rate\n",
        "print(\"Misclassification rate of Decision Tree Model: \", (((cm_dt[0][1] + cm_dt[1][0])/cm_dt.sum())*100), \"%\")"
      ],
      "metadata": {
        "id": "FPMnoDwkSKU0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking accuracy on validation dataset using model\n",
        "print(classification_report(y_val, y_val_predictions_dt))"
      ],
      "metadata": {
        "id": "IDglR7uVSMWB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model accuracy on training dataset\n",
        "Accuracy_dt_train = model_dt_history.score(X_train, y_train)\n",
        "print(\"Accuracy of Decision Tree Model- Training dataset: %.3f%%\" % (Accuracy_dt_train*100.0))"
      ],
      "metadata": {
        "id": "WDmZP4ZzSOAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model accuracy on validation dataset\n",
        "Accuracy_dt_val = model_dt_history.score(X_val, y_val)\n",
        "print(\"Accuracy of Decision Tree Model- Validation Dataset: %.3f%%\" % (Accuracy_dt_val*100.0))"
      ],
      "metadata": {
        "id": "ACgCXPnpSXwg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicting on test dataset\n",
        "y_test_dt = model_dt_history.predict(X_test)"
      ],
      "metadata": {
        "id": "IGdRJSQ4SY6z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving predictions in dataframe\n",
        "y_test_predictions_dt = pd.DataFrame()\n",
        "y_test_predictions_dt[\"id\"] = test_dataframe[\"id\"]\n",
        "y_test_predictions_dt[\"ACTION\"] = y_test_dt\n",
        "print(y_test_predictions_dt)\n",
        "\n",
        "# Saving results to csv file\n",
        "y_test_predictions_dt.to_csv(\"submission_dt.csv\", index=False)"
      ],
      "metadata": {
        "id": "82Qhc3RESc_d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding ACTION target variable for test dataframe\n",
        "count_Class_dt = y_test_predictions_dt['ACTION'].value_counts()\n",
        "print(\"Count of ACTION variable for Decision Tree: \\n\", count_Class_dt)"
      ],
      "metadata": {
        "id": "geOLTO8kSgJT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pie chart for counts of ACTION target variable for test dataframe\n",
        "count_Class_dt.plot(kind='pie', autopct='%1.0f%%')\n",
        "plt.title('Pie chart of count of ACTION variable for Decision Tree')\n",
        "plt.ylabel('')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "iV0t0qBsD_-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**d. K-Nearest Neighbors (K-NN) Model**"
      ],
      "metadata": {
        "id": "u8fxuy2DEXSn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Building K-NN model\n",
        "model_knn = KNeighborsClassifier()"
      ],
      "metadata": {
        "id": "U7x2NTHHRNrQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cross validating the K-NN model\n",
        "statistics_cv_knn = cross_validate(model_knn, X_train, y_train, groups=None, scoring='roc_auc', cv=5, n_jobs=2, return_train_score=True)\n",
        "statistics_cv_knn = pd.DataFrame(statistics_cv_knn)\n",
        "statistics_cv_knn.describe()"
      ],
      "metadata": {
        "id": "dn0wQE4RRRfJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the K-NN model\n",
        "model_knn_history = model_knn.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "VheV4LZbRUaD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion matrix for Validation dataset\n",
        "y_val_predictions_knn = model_knn_history.predict(X_val)\n",
        "cm_knn = metrics.confusion_matrix(y_val, y_val_predictions_knn)\n",
        "print(cm_knn)"
      ],
      "metadata": {
        "id": "ofcLSf8URXKc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Heat map for the confusion matrix\n",
        "plt.figure(figsize=(9,9))\n",
        "sns.heatmap(cm_knn, annot=True, fmt=\".3f\", linewidths=.5, square=True, cmap='Blues_r')\n",
        "plt.ylabel('Actual label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.title(\"Accuracy- K-Nearest Neighbors\", size=15)"
      ],
      "metadata": {
        "id": "xzpM-lzkRYSH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Misclassification rate\n",
        "print(\"Misclassification rate of K-NN Model: \", (((cm_knn[0][1] + cm_knn[1][0]) / cm_knn.sum()) * 100), \"%\")"
      ],
      "metadata": {
        "id": "UTIOxp2lRa7F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking accuracy on validation dataset using model\n",
        "print(classification_report(y_val, y_val_predictions_knn))"
      ],
      "metadata": {
        "id": "qnfZRkapRdRU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model accuracy on training dataset\n",
        "Accuracy_knn_train = model_knn_history.score(X_train, y_train)\n",
        "print(\"Accuracy of K-NN Model- Training dataset: %.3f%%\" % (Accuracy_knn_train * 100.0))"
      ],
      "metadata": {
        "id": "-xBMjSB8Rdxe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model accuracy on validation dataset\n",
        "Accuracy_knn_val = model_knn_history.score(X_val, y_val)\n",
        "print(\"Accuracy of K-NN Model- Validation Dataset: %.3f%%\" % (Accuracy_knn_val * 100.0))"
      ],
      "metadata": {
        "id": "k0lueGaQRhbF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicting on test dataset\n",
        "y_test_knn = model_knn_history.predict(X_test)"
      ],
      "metadata": {
        "id": "oo-ThMxTRkAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving predictions in dataframe\n",
        "y_test_predictions_knn = pd.DataFrame()\n",
        "y_test_predictions_knn[\"id\"] = test_dataframe[\"id\"]\n",
        "y_test_predictions_knn[\"ACTION\"] = y_test_knn\n",
        "print(y_test_predictions_knn)\n",
        "\n",
        "# Saving results to csv file\n",
        "y_test_predictions_knn.to_csv(\"submission_knn.csv\", index=False)"
      ],
      "metadata": {
        "id": "M9O0Arx0RnL4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding ACTION target variable for test dataframe\n",
        "count_Class_knn = y_test_predictions_knn['ACTION'].value_counts()\n",
        "print(\"Count of ACTION variable for K-NN: \\n\", count_Class_knn)"
      ],
      "metadata": {
        "id": "wX6KtSvmRnyw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pie chart for counts of ACTION target variable for test dataframe\n",
        "count_Class_knn.plot(kind='pie', autopct='%1.0f%%')\n",
        "plt.title('Pie chart of count of ACTION variable for K-NN')\n",
        "plt.ylabel('')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "OcMb_epBEdvI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KM4kSKcOt0it"
      },
      "source": [
        "## **4. Model Comparison and Conclusion**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1HYaQemiuBH"
      },
      "source": [
        "# Plotting accuracies of all models in a box plot\n",
        "\n",
        "Accuracy_of_allModels = {'LR': [96.03, 94.74], 'SVM': [95.76, 94.54], 'DT': [100, 94.08], 'K-NN': [96.025, 94.492]}\n",
        "df = pd.DataFrame(data=Accuracy_of_allModels)\n",
        "sns.boxplot(data=df).set(title = 'Model Comparison', xlabel = 'Models', ylabel = 'Accuracy' )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBUw6BMxpzDF"
      },
      "source": [
        "* From the analysis of all models, it's evident that each model achieves a high level of accuracy, ranging from 94.08% to 100%. However, when considering the generalization error gap, the Support Vector Machine (SVM) model demonstrates the smallest gap, indicating better generalization capability. On the other hand, the Decision Tree model exhibits a larger generalization error gap, suggesting potential overfitting. This underscores the importance of regularization techniques in improving generalization performance while maintaining high accuracy.\n",
        "\n",
        "* Considering both accuracy and generalization, the Support Vector Machine emerges as the best model. Its validation accuracy of 94.54% is slightly lower than the best-performing Linear Regression model (94.74%), but its smaller generalization gap makes it a more reliable choice for making predictions.\n"
      ]
    }
  ]
}